# -*- coding: utf-8 -*-
"""chatbot_deep_learn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17St75OYgS5oyu9moM2DN0E3_bt2tyCDx
"""

import nltk
#nltk.download('all')
import numpy as np
import json
import random
import tensorflow as tf
import tflearn
from nltk.stem import LancasterStemmer
import pickle
stemer= LancasterStemmer()

import json
with open("intents.json") as file:
  data = json.load(file)
print(data["intents"])

words = []
label = []
docx = []
docy = []

for intent in data["intents"]:
  print(intent['patterns'])
  for pattern in intent['patterns']:
    wrd = nltk.word_tokenize(pattern)  # getting words from the patterns
    
    words.extend(wrd)
    
    docx.append(wrd)
    docy.append(intent['tag'])
    

    if intent["tag"] not in label:
      label.append(intent['tag'])
    
print(words,docx,docy,label,sep = '\n')

words = [stemer.stem(w.lower()) for w in words if w != "?" or w != "<"]
words = sorted(list(set(words)))
labels = sorted(label)
print(words,labels,sep="\n")

train = []
op =[]
out_emp =[0 for _ in range(len(labels))]
for x,doc in enumerate(docx):
  bag =[]
  wrds = [stemer.stem(w) for w in doc]
  for w in words:
    if w in wrds:
      bag.append(1)
    else:
      bag.append(0)
  op_raw = out_emp[:]
  op_raw[labels.index(docy[x])] =1
  train.append(bag)
  op.append(op_raw)
print(train,op,bag,op_raw,out_emp,sep='\n')

train = np.array(train)
op = np.array(op)
with open("data.pickle","wb")as f:
  pickle.dump((words,labels,train,op),f)

#AI MODEL ASPECT
tf.compat.v1.reset_default_graph() #no idea what it do but solved teh eroor
net = tflearn.input_data(shape= [None,len(train[0])])
net = tflearn.fully_connected(net,8) #8 neurons of fully connected layerr
net = tflearn.fully_connected(net,8)
net = tflearn.fully_connected(net,len(op[0]),activation = "softmax") # last layer/op layer
net = tflearn.regression(net)

model = tflearn.DNN(net) # DNN is a type of NN

model.fit(train,op,n_epoch=500,batch_size = 8,show_metric=True)

model.save("model.tflearn")

def bag_words(w,words):
  bag = [ 0 for _ in range(len(words))]

  s_words = nltk.word_tokenize(w)
  s_words = [stemer.stem(word.lower()) for word in s_words]

  for se in s_words:
    for i,w in enumerate(words):
      if w == se:
        bag[i] = 1
  return np.array(bag)

def chat():
  print("start talk")
  while True :
    ip = input()
    while ip.lower()=="quit":
      break
    result = model.predict([bag_words(ip,words)])[0]
    rs = np.argmax(result) #getting index
    tag = labels[rs]
    print(result[rs])
    if result[rs]>0.45:

      for tg in data["intents"]:
          if tg['tag'] == tag:
            r = tg['responses']
      print(random.choice(r))
    else:
      with open("new.txt",'a') as f:
        f.write(ip)
      f.close()
      print("This made no sense to me ")

chat()
